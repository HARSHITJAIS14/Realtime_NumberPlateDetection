{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import ast\n",
    "\n",
    "\n",
    "import util\n",
    "from sort.sort import *\n",
    "from util import get_car, read_license_plate, write_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(frame, boxes):\n",
    "    x1, y1, x2, y2= boxes  # Get coordinates of the bounding box\n",
    "    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plate(frame, box):\n",
    "    x1, y1, x2, y2= box  # Get coordinates of the bounding box\n",
    "    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "  import PIL.Image\n",
    "  if not hasattr(PIL.Image, 'Resampling'):  # Pillow<9.0\n",
    "    PIL.Image.Resampling = PIL.Image\n",
    "  # Now PIL.Image.Resampling.BICUBIC is always recognized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "mot_tracker = Sort()\n",
    "\n",
    "# load models\n",
    "coco_model = YOLO('yolov8n.pt')\n",
    "license_plate_detector = YOLO('/home/harshit/Desktop/project/license_plate_detector.pt')\n",
    "\n",
    "# load video\n",
    "cap = cv2.VideoCapture('/home/harshit/Desktop/project/sample.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 22 cars, 1 bus, 3 trucks, 8.9ms\n",
      "Speed: 21.6ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 3 trucks, 5.9ms\n",
      "Speed: 1.9ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 2 trucks, 7.3ms\n",
      "Speed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 7.6ms\n",
      "Speed: 2.1ms preprocess, 7.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 6.1ms\n",
      "Speed: 2.4ms preprocess, 6.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.8ms\n",
      "Speed: 1.9ms preprocess, 5.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JED\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 3 trucks, 6.5ms\n",
      "Speed: 2.4ms preprocess, 6.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 3 trucks, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 21 cars, 3 trucks, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 1 person, 21 cars, 3 trucks, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 3 trucks, 6.3ms\n",
      "Speed: 2.0ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JED\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 6.1ms\n",
      "Speed: 2.2ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 9.2ms\n",
      "Speed: 2.6ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 6.9ms\n",
      "Speed: 2.1ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.8ms\n",
      "Speed: 1.7ms preprocess, 5.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 24 cars, 3 trucks, 8.8ms\n",
      "Speed: 2.0ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 24 cars, 3 trucks, 5.9ms\n",
      "Speed: 1.9ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 3 trucks, 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 6.5ms\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 3 trucks, 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JED\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 1 bus, 3 trucks, 6.3ms\n",
      "Speed: 1.9ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 6.4ms\n",
      "Speed: 1.9ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JED\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 2 trucks, 6.1ms\n",
      "Speed: 1.6ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEC\n",
      "None\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 2 trucks, 6.8ms\n",
      "Speed: 2.0ms preprocess, 6.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AH15ZIK\n",
      "AP05JEL\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 2 trucks, 6.1ms\n",
      "Speed: 1.8ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 6.1ms\n",
      "Speed: 2.0ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AH15ZIK\n",
      "AP05JEL\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 2 trucks, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 2 trucks, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 2 trucks, 6.1ms\n",
      "Speed: 1.6ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 3 trucks, 6.1ms\n",
      "Speed: 2.0ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 3 trucks, 6.3ms\n",
      "Speed: 1.9ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JED\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 3 trucks, 6.1ms\n",
      "Speed: 2.1ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.9ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JED\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 3 trucks, 7.9ms\n",
      "Speed: 2.0ms preprocess, 7.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 3 trucks, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEU\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 6.3ms\n",
      "Speed: 2.0ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 2.2ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 21 cars, 3 trucks, 6.1ms\n",
      "Speed: 1.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZIK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 21 cars, 3 trucks, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZTK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 21 cars, 3 trucks, 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZTK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 21 cars, 2 trucks, 6.1ms\n",
      "Speed: 1.6ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KN05ZZK\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 7.5ms\n",
      "Speed: 2.3ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 3 trucks, 6.0ms\n",
      "Speed: 2.1ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KI05ZIK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 20 cars, 1 bus, 3 trucks, 6.1ms\n",
      "Speed: 1.8ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 2.3ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 2 trucks, 6.1ms\n",
      "Speed: 1.6ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 20 cars, 1 bus, 2 trucks, 6.6ms\n",
      "Speed: 1.9ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KH05ZZX\n",
      "\n",
      "0: 384x640 20 cars, 1 bus, 2 trucks, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KR05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 22 cars, 1 bus, 2 trucks, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "RR05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 22 cars, 1 bus, 2 trucks, 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 25 cars, 2 buss, 3 trucks, 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.8ms\n",
      "Speed: 1.7ms preprocess, 5.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 3 trucks, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "RH05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 23 cars, 2 buss, 1 truck, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 24 cars, 2 buss, 1 truck, 6.5ms\n",
      "Speed: 2.1ms preprocess, 6.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 1 truck, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.8ms\n",
      "Speed: 1.7ms preprocess, 5.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KH05ZZK\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 1 truck, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KH05ZZK\n",
      "\n",
      "0: 384x640 25 cars, 1 bus, 1 truck, 6.1ms\n",
      "Speed: 1.6ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 26 cars, 1 bus, 1 truck, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 20 cars, 1 bus, 2 trucks, 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.8ms\n",
      "Speed: 2.1ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 1 truck, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KH05ZZK\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 1 truck, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.9ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 1 truck, 5.9ms\n",
      "Speed: 2.1ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 2 trucks, 6.3ms\n",
      "Speed: 1.9ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KH05ZZK\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 1 truck, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 1 truck, 6.1ms\n",
      "Speed: 1.6ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 1 truck, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.8ms\n",
      "Speed: 1.6ms preprocess, 5.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "RH05ZZK\n",
      "AP05JED\n",
      "\n",
      "0: 384x640 23 cars, 2 buss, 2 trucks, 6.1ms\n",
      "Speed: 2.1ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "RH05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 24 cars, 2 buss, 2 trucks, 6.1ms\n",
      "Speed: 1.6ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "RH05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 22 cars, 2 buss, 2 trucks, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEQ\n",
      "\n",
      "0: 384x640 22 cars, 2 buss, 1 truck, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 6.2ms\n",
      "Speed: 1.9ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEQ\n",
      "\n",
      "0: 384x640 23 cars, 2 buss, 1 truck, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KR05ZZK\n",
      "\n",
      "0: 384x640 25 cars, 1 bus, 2 trucks, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 6.3ms\n",
      "Speed: 2.0ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KK05ZZK\n",
      "\n",
      "0: 384x640 21 cars, 3 trucks, 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 6.5ms\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "RN05ZZK\n",
      "\n",
      "0: 384x640 21 cars, 3 trucks, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "RN05ZZK\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 3 trucks, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 6.1ms\n",
      "Speed: 2.0ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEQ\n",
      "\n",
      "0: 384x640 23 cars, 3 trucks, 6.2ms\n",
      "Speed: 2.3ms preprocess, 6.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZIK\n",
      "AP05JEQ\n",
      "\n",
      "0: 384x640 21 cars, 3 trucks, 5.9ms\n",
      "Speed: 2.0ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEQ\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 2 trucks, 7.8ms\n",
      "Speed: 2.1ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.8ms\n",
      "Speed: 1.6ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KN05ZIK\n",
      "AP05JEQ\n",
      "\n",
      "0: 384x640 20 cars, 2 trucks, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.8ms\n",
      "Speed: 1.9ms preprocess, 5.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KM05ZZK\n",
      "AP05JEQ\n",
      "\n",
      "0: 384x640 21 cars, 3 trucks, 5.9ms\n",
      "Speed: 2.0ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZTK\n",
      "AP05JEQ\n",
      "\n",
      "0: 384x640 21 cars, 4 trucks, 6.1ms\n",
      "Speed: 1.8ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.8ms\n",
      "Speed: 2.2ms preprocess, 5.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 6.1ms\n",
      "Speed: 1.8ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KA05ZZK\n",
      "\n",
      "0: 384x640 25 cars, 2 trucks, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KA05ZZK\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KA05ZZK\n",
      "\n",
      "0: 384x640 24 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KA05ZZK\n",
      "\n",
      "0: 384x640 23 cars, 4 trucks, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 2.0ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEQ\n",
      "KR05ZZK\n",
      "\n",
      "0: 384x640 23 cars, 3 trucks, 6.1ms\n",
      "Speed: 1.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KR05ZIK\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 2 trucks, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "None\n",
      "\n",
      "0: 384x640 25 cars, 1 bus, 1 truck, 7.1ms\n",
      "Speed: 1.9ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KK05ZZK\n",
      "AP05JED\n",
      "\n",
      "0: 384x640 25 cars, 1 bus, 2 trucks, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 25 cars, 1 bus, 2 trucks, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 25 cars, 1 bus, 2 trucks, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.8ms\n",
      "Speed: 1.6ms preprocess, 5.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 25 cars, 1 bus, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 6.5ms\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEQ\n",
      "\n",
      "0: 384x640 22 cars, 1 bus, 1 truck, 6.1ms\n",
      "Speed: 2.0ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEQ\n",
      "None\n",
      "\n",
      "0: 384x640 25 cars, 1 bus, 1 truck, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEQ\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 2 trucks, 7.2ms\n",
      "Speed: 2.2ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEQ\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 2 trucks, 6.1ms\n",
      "Speed: 1.8ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEQ\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 2 trucks, 6.2ms\n",
      "Speed: 1.9ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 1 truck, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 6.3ms\n",
      "Speed: 1.9ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 2 trucks, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEQ\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 2 trucks, 6.1ms\n",
      "Speed: 2.2ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.9ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEQ\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 1 truck, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 1 truck, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 1 truck, 6.1ms\n",
      "Speed: 2.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 1 truck, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.8ms\n",
      "Speed: 1.6ms preprocess, 5.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 26 cars, 1 bus, 1 truck, 7.3ms\n",
      "Speed: 2.2ms preprocess, 7.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 8.3ms\n",
      "Speed: 2.2ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 1 truck, 8.8ms\n",
      "Speed: 2.5ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 7.2ms\n",
      "Speed: 2.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 1 truck, 9.0ms\n",
      "Speed: 2.7ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KH05ZZK\n",
      "\n",
      "0: 384x640 22 cars, 1 bus, 1 truck, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AP05JEO\n",
      "KH05ZZK\n",
      "\n",
      "0: 384x640 26 cars, 1 bus, 1 truck, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 2.0ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 1 truck, 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 22 cars, 1 bus, 1 truck, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.9ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KN05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 1 truck, 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KA05ZZK\n",
      "\n",
      "0: 384x640 26 cars, 1 bus, 2 trucks, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KA05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 26 cars, 1 bus, 2 trucks, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KA05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 2 trucks, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.9ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KR05ZZK\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 2 trucks, 6.5ms\n",
      "Speed: 2.4ms preprocess, 6.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "AP05JEO\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 2 trucks, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 2 trucks, 6.2ms\n",
      "Speed: 2.6ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 5.7ms\n",
      "Speed: 2.1ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KN05ZZK\n",
      "None\n",
      "\n",
      "0: 384x640 20 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 20 cars, 2 trucks, 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 2 trucks, 8.5ms\n",
      "Speed: 2.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 2.3ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 2 trucks, 7.7ms\n",
      "Speed: 2.8ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 5.7ms\n",
      "Speed: 2.0ms preprocess, 5.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KN05ZZK\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 2 trucks, 7.6ms\n",
      "Speed: 2.4ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 2 trucks, 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KN05ZZK\n",
      "None\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 2 trucks, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 2 trucks, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.9ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 2 trucks, 6.6ms\n",
      "Speed: 2.7ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 9.2ms\n",
      "Speed: 2.4ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 17 cars, 2 trucks, 8.2ms\n",
      "Speed: 2.5ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 6.7ms\n",
      "Speed: 2.3ms preprocess, 6.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 17 cars, 1 bus, 2 trucks, 9.0ms\n",
      "Speed: 2.5ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 8.2ms\n",
      "Speed: 2.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 17 cars, 1 bus, 2 trucks, 8.6ms\n",
      "Speed: 2.5ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 20 cars, 2 trucks, 8.5ms\n",
      "Speed: 2.5ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 20 cars, 2 trucks, 8.9ms\n",
      "Speed: 2.0ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 8.7ms\n",
      "Speed: 2.4ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 20 cars, 2 trucks, 8.4ms\n",
      "Speed: 2.5ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 9.1ms\n",
      "Speed: 2.4ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 2 trucks, 6.7ms\n",
      "Speed: 1.9ms preprocess, 6.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 9.1ms\n",
      "Speed: 2.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 8.8ms\n",
      "Speed: 2.5ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 7.7ms\n",
      "Speed: 2.0ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 8.2ms\n",
      "Speed: 2.5ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 9.3ms\n",
      "Speed: 2.4ms preprocess, 9.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 8.5ms\n",
      "Speed: 2.5ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 2.0ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 25 cars, 2 trucks, 7.5ms\n",
      "Speed: 2.4ms preprocess, 7.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 8.3ms\n",
      "Speed: 2.4ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 24 cars, 2 trucks, 7.4ms\n",
      "Speed: 2.5ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 24 cars, 2 trucks, 7.5ms\n",
      "Speed: 2.5ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 26 cars, 2 trucks, 8.2ms\n",
      "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 8.2ms\n",
      "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 25 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "RH05ZZK\n",
      "\n",
      "0: 384x640 24 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "RH05ZZK\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 6.1ms\n",
      "Speed: 1.8ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "WR02FKL\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 7.6ms\n",
      "Speed: 2.4ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZZK\n",
      "None\n",
      "\n",
      "0: 384x640 24 cars, 2 trucks, 7.6ms\n",
      "Speed: 2.5ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "RH05ZZK\n",
      "None\n",
      "\n",
      "0: 384x640 24 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "RH05ZZK\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 7.8ms\n",
      "Speed: 2.4ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "RH05ZZK\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 7.9ms\n",
      "Speed: 2.0ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 8.3ms\n",
      "Speed: 2.4ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 8.2ms\n",
      "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 20 cars, 2 trucks, 9.0ms\n",
      "Speed: 2.7ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "RH05ZZK\n",
      "None\n",
      "\n",
      "0: 384x640 20 cars, 2 trucks, 8.2ms\n",
      "Speed: 2.5ms preprocess, 8.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "RH05ZZK\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 2 trucks, 8.8ms\n",
      "Speed: 2.7ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "RH05ZZK\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "VR02FKD\n",
      "\n",
      "0: 384x640 21 cars, 2 trucks, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 2 trucks, 13.0ms\n",
      "Speed: 2.6ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 19 cars, 2 trucks, 7.5ms\n",
      "Speed: 2.5ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.9ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 18 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 19 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.9ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 19 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 19 cars, 2 trucks, 8.5ms\n",
      "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 8.3ms\n",
      "Speed: 2.4ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 19 cars, 2 trucks, 8.7ms\n",
      "Speed: 2.5ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 20 cars, 2 trucks, 9.2ms\n",
      "Speed: 2.5ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 20 cars, 2 trucks, 7.1ms\n",
      "Speed: 2.6ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 2 trucks, 6.0ms\n",
      "Speed: 2.1ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 2 trucks, 7.5ms\n",
      "Speed: 2.5ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.6ms\n",
      "Speed: 1.6ms preprocess, 5.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 8.2ms\n",
      "Speed: 2.4ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "KH05ZAK\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 11.2ms\n",
      "Speed: 2.1ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 6.7ms\n",
      "Speed: 2.2ms preprocess, 6.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 20 cars, 3 trucks, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 21 cars, 2 trucks, 6.0ms\n",
      "Speed: 2.3ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 5.7ms\n",
      "Speed: 1.9ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 8.4ms\n",
      "Speed: 2.5ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 8.9ms\n",
      "Speed: 2.6ms preprocess, 8.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 8.9ms\n",
      "Speed: 2.6ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 6.1ms\n",
      "Speed: 2.4ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 24 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 25 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 26 cars, 2 trucks, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 24 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 7.3ms\n",
      "Speed: 2.9ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.8ms\n",
      "Speed: 1.8ms preprocess, 5.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 24 cars, 2 trucks, 8.2ms\n",
      "Speed: 2.6ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 7.5ms\n",
      "Speed: 2.4ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 0, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "\n",
      "0: 384x640 23 cars, 2 trucks, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 5.7ms\n",
      "Speed: 1.9ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "None\n",
      "\n",
      "0: 384x640 22 cars, 2 trucks, 9.3ms\n",
      "Speed: 2.7ms preprocess, 9.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 7.1ms\n",
      "Speed: 2.1ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7639/602528869.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0;31m# read license plate number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mlicense_plate_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlicense_plate_text_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_license_plate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlicense_plate_crop_thresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlicense_plate_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project/util.py\u001b[0m in \u001b[0;36mread_license_plate\u001b[0;34m(license_plate_crop)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlicense_plate_crop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdetection\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/easyocr/easyocr.py\u001b[0m in \u001b[0;36mreadtext\u001b[0;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cv_grey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreformat_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         horizontal_list, free_list = self.detect(img, \n\u001b[0m\u001b[1;32m    457\u001b[0m                                                  \u001b[0mmin_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                                                  \u001b[0mlow_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlow_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/easyocr/easyocr.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, img, min_size, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, add_margin, reformat, optimal_num_chars, threshold, bbox_min_score, bbox_min_size, max_candidates)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cv_grey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreformat_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         text_box_list = self.get_textbox(self.detector, \n\u001b[0m\u001b[1;32m    322\u001b[0m                                     \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                                     \u001b[0mcanvas_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanvas_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/easyocr/detection.py\u001b[0m in \u001b[0;36mget_textbox\u001b[0;34m(detector, image, canvas_size, mag_ratio, text_threshold, link_threshold, low_text, poly, device, optimal_num_chars, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mestimate_num_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimal_num_chars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     bboxes_list, polys_list = test_net(canvas_size, mag_ratio, detector,\n\u001b[0m\u001b[1;32m     96\u001b[0m                                        \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                                        \u001b[0mlink_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/easyocr/detection.py\u001b[0m in \u001b[0;36mtest_net\u001b[0;34m(canvas_size, mag_ratio, net, image, text_threshold, link_threshold, low_text, poly, device, estimate_num_chars)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mboxes_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolys_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/easyocr/craft.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;34m\"\"\" Base network \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0msources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;34m\"\"\" U network \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/easyocr/model/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mh_relu3_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mh_relu4_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vehicles = [2, 3, 5, 7]\n",
    "\n",
    "# read frames\n",
    "frame_nmr = -1\n",
    "ret = True\n",
    "import time\n",
    "while ret:\n",
    "    start_time = time.time()\n",
    "    frame_nmr += 1\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        results[frame_nmr] = {}\n",
    "        # detect vehicles\n",
    "        detections = coco_model(frame)[0]\n",
    "        detections_ = []\n",
    "        for detection in detections.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = detection\n",
    "\n",
    "            if int(class_id) in vehicles:\n",
    "                detections_.append([x1, y1, x2, y2, score])\n",
    "\n",
    "            # track vehicles\n",
    "        track_ids = mot_tracker.update(np.asarray(detections_))\n",
    "        # draw_boxes(frame,detections_)\n",
    "            # detect license plates\n",
    "        license_plates = license_plate_detector(frame)[0]\n",
    "        for license_plate in license_plates.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = license_plate\n",
    "            # draw_plate(frame,[int(x1),int(y1),int(x2),int(y2),0])\n",
    "                # assign license plate to car\n",
    "            xcar1, ycar1, xcar2, ycar2, car_id = get_car(license_plate, track_ids)\n",
    "\n",
    "            if car_id != -1:\n",
    "\n",
    "                    # crop license plate\n",
    "                license_plate_crop = frame[int(y1):int(y2), int(x1): int(x2), :]\n",
    "\n",
    "                    # process license plate\n",
    "                license_plate_crop_gray = cv2.cvtColor(license_plate_crop, cv2.COLOR_BGR2GRAY)\n",
    "                _, license_plate_crop_thresh = cv2.threshold(license_plate_crop_gray, 64, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "                    # read license plate number\n",
    "                license_plate_text, license_plate_text_score = read_license_plate(license_plate_crop_thresh)\n",
    "                print(license_plate_text)\n",
    "\n",
    "                if license_plate_text is not None:\n",
    "                    results[frame_nmr][car_id] = {'car': {'bbox': [xcar1, ycar1, xcar2, ycar2]},\n",
    "                                                'license_plate': {'bbox': [x1, y1, x2, y2],\n",
    "                                                                    'text': license_plate_text,\n",
    "                                                                    'bbox_score': score,\n",
    "                                                                    'text_score': license_plate_text_score}}\n",
    "                    car_bbox = results[frame_nmr][car_id]['car']['bbox']\n",
    "                    license_plate_bbox = results[frame_nmr][car_id]['license_plate']['bbox']\n",
    "                    draw_boxes(frame,car_bbox)\n",
    "                    draw_plate(frame,license_plate_bbox)\n",
    "\n",
    "                    H, W, _ = license_plate_crop.shape\n",
    "                    # import ast\n",
    "\n",
    "                    # Assuming results is a dictionary\n",
    "                    # Assuming results is a dictionary\n",
    "                    car_bbox = results[frame_nmr][car_id]['car']['bbox']\n",
    "                    car_x1, car_y1, car_x2, car_y2 = car_bbox  # Unpack the list directly\n",
    "\n",
    "\n",
    "                    # Now you have car_x1, car_y1, car_x2, car_y2 containing the bbox coordinates\n",
    "                    # Assuming results is a dictionary\n",
    "                    license_plate_bbox = results[frame_nmr][car_id]['license_plate']['bbox']\n",
    "                    x1, y1, x2, y2 = license_plate_bbox  # Unpack the list directly\n",
    "\n",
    "\n",
    "                    try:\n",
    "                        frame[int(car_y1) - H - 100:int(car_y1) - 100,\n",
    "                            int((car_x2 + car_x1 - W) / 2):int((car_x2 + car_x1 + W) / 2), :] = license_plate_crop\n",
    "\n",
    "                        frame[int(car_y1) - H - 400:int(car_y1) - H - 100,\n",
    "                            int((car_x2 + car_x1 - W) / 2):int((car_x2 + car_x1 + W) / 2), :] = (255, 255, 255)\n",
    "\n",
    "                      # Calculate the text width and height\n",
    "                        (text_width, text_height), _ = cv2.getTextSize(\n",
    "                                                        license_plate_text,\n",
    "                                                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                                        4.3,\n",
    "                                                        17)\n",
    "\n",
    "\n",
    "                        # Assuming license_plate_bbox is a tuple or list containing (x1, y1, x2, y2) coordinates\n",
    "                        license_plate_bbox = results[frame_nmr][car_id]['license_plate']['bbox']\n",
    "                        x1, y1, x2, y2 = license_plate_bbox\n",
    "\n",
    "                        # Get the license plate number from the DataFrame\n",
    "                        license_plate_number = license_plate_text\n",
    "\n",
    "                        # Calculate the position to put the text\n",
    "                        text_width, text_height = cv2.getTextSize(license_plate_number, cv2.FONT_HERSHEY_SIMPLEX, 4.3, 17)[0]\n",
    "                        text_position = ((x2 + x1 - text_width) // 2, (y1 - 250 + text_height) // 2)\n",
    "\n",
    "                        # Put the text on the frame\n",
    "                        cv2.putText(frame,\n",
    "                                license_plate_text,\n",
    "                                (int((car_x2 + car_x1 - text_width) / 2), int(car_y1 - H - 250 + (text_height / 2))),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                4.3,\n",
    "                                (0, 0, 0),\n",
    "                                17)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "                    width = 800  # Desired width\n",
    "                    height = 600  # Desired height\n",
    "                    resized_image = cv2.resize(frame, (width, height))\n",
    "                    # Display the resized image with a specific window size\n",
    "                    cv2.namedWindow('Resized Image', cv2.WINDOW_NORMAL)  # Create a resizable window\n",
    "                    cv2.imshow('Resized Image', resized_image)\n",
    "                            # Check for 'q' key to exit\n",
    "                    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                     break\n",
    "  \n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time:\", execution_time, \"seconds\") \n",
    "cv2.destroyAllWindows()    \n",
    "\n",
    " \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_nmr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(results,'/home/harshit/Desktop/project/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
